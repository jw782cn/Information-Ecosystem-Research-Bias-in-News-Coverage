{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/avsorokina/en-articles.csv')\n",
    "df_nyt = pd.read_csv('/Users/avsorokina/en-nyt-articles.csv')\n",
    "df_ru = pd.read_csv('/Users/avsorokina/ru-articles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()\n",
    "df_nyt = df_nyt.drop_duplicates()\n",
    "df_ru = df_ru.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenta_urls = list(set(df_ru[df_ru.source == 'Lenta']['url']))\n",
    "rbc_urls = list(set(df_ru[df_ru.source == 'RBC']['url']))\n",
    "rt_urls = list(set(df_ru[df_ru.source == 'RT']['url']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "usa_today_urls = df[df.source == 'USA Today'].reset_index()['url']\n",
    "wp_urls = df[df.source == 'The Washington Post'].reset_index()['url']\n",
    "wsj_urls = df[df.source == 'The Wall Street Journal'].reset_index()['url']\n",
    "nyt_urls = df_nyt['url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "usa_today_urls = [a for a in usa_today_urls if 'restricted' not in a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.washingtonpost.com/world/2022/03/26/russia-detention-american-minnesota-teacher-ukraine/'\n",
    "page = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = soup.find_all('div', {'class': 'article-body'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## USA today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "usa_today_texts2 = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "usa_today_urls_unique = list(set(usa_today_urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vd/8vk_qp5n693gjqqjh63dqr5h0000gn/T/ipykernel_82998/1092554760.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  usa_today_texts2 = usa_today_texts2.append(pd.Series([url, texts]),  ignore_index=True)\n",
      "/var/folders/vd/8vk_qp5n693gjqqjh63dqr5h0000gn/T/ipykernel_82998/1092554760.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  usa_today_texts2 = usa_today_texts2.append(pd.Series([url, texts]),  ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "for url in usa_today_urls_unique:\n",
    "    texts = []\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    table = soup.find_all('div', {'class': 'gnt_ar_b'})\n",
    "    for a in table:\n",
    "        texts.append(a.find('p').text)\n",
    "\n",
    "    table2 = soup.find_all('p', {'class': 'gnt_ar_b_p'})\n",
    "    for a in table2:\n",
    "        if a.text not in texts:\n",
    "            texts.append(a.text)\n",
    "    \n",
    "    usa_today_texts2 = usa_today_texts2.append(pd.Series([url, texts]),  ignore_index=True)\n",
    "    usa_today_texts2.to_csv('usa_today_texts2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "usa_today_texts_clean = usa_today_texts2.loc[~(usa_today_texts2[1].str.len() == 0),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "usa_today_texts_clean.columns = ['url', 'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_texts = []\n",
    "for t in usa_today_texts_clean['text']:\n",
    "    if len(t) > 1:\n",
    "        comb_texts.append(' '.join(t))\n",
    "    else:\n",
    "        comb_texts.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vd/8vk_qp5n693gjqqjh63dqr5h0000gn/T/ipykernel_82998/3526108239.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  usa_today_texts_clean['text'] = comb_texts\n"
     ]
    }
   ],
   "source": [
    "usa_today_texts_clean['text'] = comb_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "usa_today_texts_clean.to_csv('usa_today_texts_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Washington Post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "wp_urls_unique = list(set(wp_urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "wp_texts = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vd/8vk_qp5n693gjqqjh63dqr5h0000gn/T/ipykernel_82998/647009735.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  wp_texts = wp_texts.append(pd.Series([url, texts]),  ignore_index=True)\n",
      "/var/folders/vd/8vk_qp5n693gjqqjh63dqr5h0000gn/T/ipykernel_82998/647009735.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  wp_texts = wp_texts.append(pd.Series([url, texts]),  ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "for url in wp_urls_unique:\n",
    "    texts = []\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    table = soup.find_all('div', {'class': 'article-body'})\n",
    "    for a in table:\n",
    "        texts.append(a.text)\n",
    "    \n",
    "    wp_texts = wp_texts.append(pd.Series([url, texts]),  ignore_index=True)\n",
    "    wp_texts.to_csv('wp_texts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "wp_texts = wp_texts.loc[~(wp_texts[1].str.len() == 0),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "wp_texts.columns = ['url', 'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_texts = []\n",
    "for t in wp_texts['text']:\n",
    "    if len(t) > 1:\n",
    "        comb_texts.append(' '.join(t))\n",
    "    else:\n",
    "        comb_texts.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_comb_texts = []\n",
    "for s in comb_texts:\n",
    "    new_comb_texts.append(\" \".join(s.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vd/8vk_qp5n693gjqqjh63dqr5h0000gn/T/ipykernel_82998/3713873619.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  wp_texts['text'] = new_comb_texts\n"
     ]
    }
   ],
   "source": [
    "wp_texts['text'] = new_comb_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "wp_texts.to_csv('wp_texts_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NYT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyt_urls_unique = list(set(nyt_urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyt_texts = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vd/8vk_qp5n693gjqqjh63dqr5h0000gn/T/ipykernel_82998/1392798131.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  nyt_texts = nyt_texts.append(pd.Series(my_list), ignore_index=True)\n",
      "/var/folders/vd/8vk_qp5n693gjqqjh63dqr5h0000gn/T/ipykernel_82998/1392798131.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  nyt_texts = nyt_texts.append(pd.Series(my_list), ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "for url in nyt_urls_unique:\n",
    "    api_url = 'https://www.page2api.com/api/v1/scrape'\n",
    "    url = url\n",
    "    payload = {\n",
    "    \"api_key\": \"cb222cbe6cf15301d8fc6e6b2373b9f5961d1978\",\n",
    "    \"url\": url,\n",
    "    \"premium_proxy\": \"us\",\n",
    "    \"parse\": {\n",
    "        \"description\": \"section.meteredContent.css-1r7ky0e >> text\"\n",
    "    }\n",
    "    }\n",
    "\n",
    "    headers = {'Content-type': 'application/json', 'Accept': 'text/plain'}\n",
    "    response = requests.post(api_url, data=json.dumps(payload), headers=headers)\n",
    "    result = json.loads(response.text)\n",
    "    if result['result'] is not None:\n",
    "        my_list = [result['result']['description'], url]\n",
    "        nyt_texts = nyt_texts.append(pd.Series(my_list), ignore_index=True)\n",
    "        nyt_texts.to_csv('nyt_texts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyt_texts.columns = ['text', 'url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyt_texts.dropna().to_csv('nyt_texts_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lenta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenta_texts = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vd/8vk_qp5n693gjqqjh63dqr5h0000gn/T/ipykernel_82998/1347338952.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  lenta_texts = lenta_texts.append(pd.Series([url, texts]),  ignore_index=True)\n",
      "/var/folders/vd/8vk_qp5n693gjqqjh63dqr5h0000gn/T/ipykernel_82998/1347338952.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  lenta_texts = lenta_texts.append(pd.Series([url, texts]),  ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "for url in lenta_urls:\n",
    "    texts = []\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    table = soup.find_all('p', {'class': 'topic-body__content-text'})\n",
    "    for a in table:\n",
    "        texts.append(a.text)\n",
    "    \n",
    "    lenta_texts = lenta_texts.append(pd.Series([url, texts]),  ignore_index=True)\n",
    "    lenta_texts.to_csv('lenta_texts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenta_texts = lenta_texts.loc[~(lenta_texts[1].str.len() == 0),:]\n",
    "\n",
    "lenta_texts.columns = ['url', 'text']\n",
    "\n",
    "comb_texts = []\n",
    "for t in lenta_texts['text']:\n",
    "    if len(t) > 1:\n",
    "        comb_texts.append(' '.join(t))\n",
    "    else:\n",
    "        comb_texts.append(t)\n",
    "\n",
    "new_comb_texts = []\n",
    "for s in comb_texts:\n",
    "    new_comb_texts.append(\" \".join(s.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenta_texts['text'] = new_comb_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenta_texts.to_csv('lenta_texts_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbc_texts = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vd/8vk_qp5n693gjqqjh63dqr5h0000gn/T/ipykernel_82998/1167068182.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  rbc_texts = rbc_texts.append(pd.Series([url, texts]),  ignore_index=True)\n",
      "/var/folders/vd/8vk_qp5n693gjqqjh63dqr5h0000gn/T/ipykernel_82998/1167068182.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  rbc_texts = rbc_texts.append(pd.Series([url, texts]),  ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "for url in rbc_urls:\n",
    "    texts = []\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    table = soup.find_all('div', {'class': 'article__text article__text_free'})\n",
    "    for a in table:\n",
    "        for b in a.find_all('p'):\n",
    "            texts.append(b.text)\n",
    "\n",
    "    rbc_texts = rbc_texts.append(pd.Series([url, texts]),  ignore_index=True)\n",
    "    rbc_texts.to_csv('rbc_texts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbc_texts = rbc_texts.loc[~(rbc_texts[1].str.len() == 0),:]\n",
    "\n",
    "rbc_texts.columns = ['url', 'text']\n",
    "\n",
    "comb_texts = []\n",
    "for t in rbc_texts['text']:\n",
    "    if len(t) > 1:\n",
    "        comb_texts.append(' '.join(t))\n",
    "    else:\n",
    "        comb_texts.append(t)\n",
    "\n",
    "new_comb_texts = []\n",
    "for s in comb_texts:\n",
    "    new_comb_texts.append(\" \".join(s.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbc_texts['text'] = new_comb_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbc_texts.to_csv('rbc_texts_df.csv')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "67fe121e0feb4a3136a0815d891ce861c9f1529202b497e284e9ae1b477edde1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('DL4-GsspAlnK')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
